# K-fold-Cross-Validation-on-KNN
Cross-validation is when the dataset is randomly split up into 'k' groups. One of the groups is used as the test set and the rest are used as the training set. The model is trained on the training set and scored on the test set. This project involves implementing Custom RandomSearchCV, plotting hyper-parameter vs accuracy plots, choosing the best hyperparameter, and then lastly plotting the decision boundaries for the model initialized with the best hyperparameter. Some of the libraries used in this project are NumPy, sklearn, tqdm, random, and matplotlib. 
